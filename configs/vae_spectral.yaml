name: ???
rundir: "${dir:runtime}/saves/${name}"

hydra:
  job:
    name: "${name}"
  run:
    dir: "${rundir}/${name}"
  sweep:
    dir: "${dir:runtime}/saves/${name}"
    subdir: "${base:${data.dataset.root}}"

defaults:
  - data:
    - defaults
    - dataset/audio
    - transforms/dgt-1024
  - model: vae
  - callbacks: audio_defaults
  - _self_

data:
  transforms: 
    name: dgt-1024
    pre_transforms:
      - {type: Mono, args: {squeeze: 1}}
      - {type: DGT, args: {n_fft: &n_fft 2048, hop_length: 512}}
#      - {type: MelMagnitude, args: {nfft: 2048, contrast: log, normalize: {mode: unipolar}}}
    transforms: 
      - {type: Magnitude, args: {contrast: log1p, n_fft: *n_fft, mel: 1, mode: unipolar}}
      - {type: Unsqueeze, args: {dim: -2}}
  dataset:
    flatten: -2
    # for learning single data spectral frames, the data can be whether flattened of randomly picked in each file. For the
    # second case, rather uncomment the sequence section.
    #sequence:
    #  length: 1
    #  mode: random
    #  idx: -2
  loader:
    batch_size: 256
    num_workers: 16

# here we add specific parameters for the decoder's output (softplus + normal distribution).
model:
  latent:
    dist: Normal
    dim: 32
  decoder:
    args:
      out_nnlin: Softplus
      target_dist: Normal
  training: 
    beta: 1.0
    beta_schedule_type: batch
    warmup: 40000

pl_trainer:
  max_epochs: 1e5
  # limit_train_batches: 1
  # limit_val_batches: 1

callbacks:
  - { type: LearningRateMonitor, args: {logging_interval: "epoch"} }
  - { type: ModelSummary, args: {max_depth: 1} }
  - { type: ModelCheckpoint, args: {dirpath: "${hydra:run.dir}", filename: "${hydra:job.name}", every_n_epochs: 1, save_last: True}}
  - { type: DissectionMonitor, args: {monitor_epochs: 10, embedding_epochs: 10, n_batches: 5, batch_size: 512} }
  - { type: AudioReconstructionMonitor, args: {reconstruction_epochs: 1, monitor_epochs: 1, plot_reconstructions: 1, plot_samples: 1, generate_files: 1, generate_trajs: 0}}

