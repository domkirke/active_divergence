name: ??
rundir: "${dir:runtime}/saves/${name}"

hydra:
  job:
    name: "${name}"
  run:
    dir: "${rundir}"
  sweep:
    dir: "${dir:runtime}/saves/${name}"
    subdir: "${base:${data.dataset.root}}"

defaults:
  - data:
    - defaults
  - model: 
    - progressive_gan
  - _self_

data:
  dataset:
    sr: 16000
    bitrate: 16
    min_length: 32000
    sequence:
      length: 256
      mode: random
      idx: -2
  transforms:
    name: stft1024_16k
    force: 1
    pre_transforms:
      - {type: Mono, args: {squeeze: 1}}
      - {type: STFT, args: {nfft: 1024, hop_size: 256}}
    transforms:
      - {type: PolarMel, args: {mag_options : {n_fft: 1024, sample_rate: 16000, contrast: log, normalize: {mode: bipolar}, keep_nyquist: True},
                                    phase_options: {normalize: {mode: bipolar}, keep_nyquist: True}, 
                                    stack: -3}}

model:
  discriminator:
    args:
      norm: none
      channels: [64,128,256,512]
      kernel_size: 25
      stride: 2
  generator:
    args:
      norm: none
      channels: [64,128,256,512]
      kernel_size: 5
      stride: 2
      out_nnlin: Tanh
  latent:
    dim: 128
    dist: Normal
    concat_metadata: {pitch: {dim: 12, type: int, idx: -3 }}
  training:
    training_schedule: [100,300,500]
    transition_schedule: [50,100,200]
    mode: wasserstein
    gp: 10.0

pl_trainer:
  max_epochs: 1e5
  #limit_train_batches: 1
  #limit_val_batches: 1

callbacks:
  - { type: LearningRateMonitor, args: {logging_interval: "epoch"} }
  - { type: ModelSummary, args: {max_depth: 1} }
  - { type: ModelCheckpoint, args: {dirpath: "${hydra:run.dir}", filename: "${hydra:job.name}", every_n_epochs: 1, save_last: True, epoch_schedule: [0, 1, 2, 3, 5, 10, 15, 20, 25, 30, 35, 40, 50]} }
  - { type: DissectionMonitor, args: {monitor_epochs: 10, embedding_epochs: 10, n_batches: 5, batch_size: 512} }
  - { type: AudioReconstructionMonitor, args: {plot_reconstructions: 1, plot_samples: 1, generate_files: 1, generate_samples: 1}}