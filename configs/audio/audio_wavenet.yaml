data:
  module: SingleAudioDataModule
  dataset:
    path: additive.wav
    sr: 44100
    bitrate: 16
    chunk_size: 2048
    n_batches: 16384
  transforms:
    transforms: [{type: MuLaw, args: {channels: &input_channels 256}}]

  loader:
    batch_size: 128
    num_workers: 0
    shuffle: 1

model:
  type: AutoRegressive
  autoregressive: 
    type: WaveNet
    args: 
      nlayers: 2
      batch: norm
      nnlin: ReLU
      input_channels: *input_channels
      residual_channels: 16
      dilation_channels: 16
      skip_channels: 128
      end_channels: 128
      block_args:
        kernel_size: 2
        type: WavenetConvBlock
        layer: GatedConvLayer
        n_convs_per_block: 9
        nnlin: Tanh
        dilation_rate: 2 
      out_nnlin: Tanh
  training:
    lr: 1.e-4
    save:
      path: &dir /slow-1/axel/active_divergence/audio
      name: &name wavenet
  losses:
    [
      {type: LogDensity, weight: 1.0},
    ]

callbacks:
  [
    { type: LearningRateMonitor, args: {logging_interval: "epoch"} },
    { type: ModelSummary, args: {max_depth: 1} },
    { type: ModelCheckpoint, args: {dirpath: *dir, filename: *name, every_n_epochs: 1, save_last: True, epoch_period: 10} },
    { type: DissectionMonitor, args: {monitor_epochs: 1, embedding_epochs: 10, batch_size: 1024} },
    { type: AudioReconstructionMonitor, args: {generate_files: 1, n_files: 1} }
  ]
      