data:
  module: AudioDataModule
  dataset:
    root: /fast-2/datasets/VoiceDataset
    #root: tests/acidsInstruments-test
    sr: 44100
    check_folder: 0
#    flatten: -2
    sequence: 
      length: 1
      idx: -2
  transforms:
    force: 0
    name: stft-1024
    pre_transforms: [{type: Mono, args: {squeeze: 1}},
                     {type: STFT, args: {nfft: 1024, hop_size: 256}}]
                     #{type: NSGT, args: {bins: 96, ls: *target_length, downsample: 10}}]
    transforms: [{type: Magnitude, args:{contrast: log, normalize: {mode: gaussian, scale: unipolar}}},
                 {type: Unsqueeze, args: {dim: -2}}]
  loader:
    batch_size: 64
    num_workers: 16
    shuffle: 1

model:
  type: AutoEncoder
  encoder:
    #type: MLPEncoder
    #args:
    #  nlayers: 2
    #  dims: 800
    #  nnlin: ELU
    type: ConvEncoder
    args:
      channels: [64,64,64,64,128,128]
      dilation: [1,1,1,1,1]
      stride: [1,2,2,4,4]
      kernel_size: [3,5,5,7,7]
      nnlin: ELU
      bias: False
  decoder:
    #type: MLPEncoder
    #args:
    #  nlayers: 2
    #  dims: 800
    #  nnlin: ELU
    #  out_nnlin: Softplus
    #  target_dist: Normal
    type: DeconvEncoder
    args: 
      channels: [64,64,64,64,128,128]
      dilation: [1,1,1,1,1]
      stride: [1,2,2,4,4]
      kernel_size: [7,7,7,9,9]
      norm: batch
      bias: False
      nnlin: ELU
      out_nnlin: Softplus
      block_args:
        conv_class: weighted
  latent:
    dist: Normal
    dim: 16
  training:
    reconstruction:
      type: MSE
    regularization:
      type: KLD
    optimizer:
      type: Adam
      args:
        lr: 1.e-4
    scheduler:
      type: ReduceLROnPlateau
      args:
        patience: 10
        factor: 0.1
    lr: 1.e-4
    beta: 1.0
    warmup: 1000
    save:
      path: &dir /slow-1/axel/active_divergence/audio
      name: &name voice-vae-mse

callbacks:
  [
    { type: LearningRateMonitor, args: {logging_interval: "epoch"} },
    { type: ModelSummary, args: {max_depth: 1} },
    { type: ModelCheckpoint, args: {dirpath: *dir, filename: *name, monitor: "loss/valid", save_last: True, epoch_schedule: [0, 1, 5, 10, 15, 20, 30, 50, 100, 200, 500]}},
    { type: DissectionMonitor, args: {monitor_epochs: 10, embedding_epochs: 10, n_batches: 5, batch_size: 512} },
    { type: AudioReconstructionMonitor, args: {plot_reconstructions: 1, plot_samples: 0, generate_samples: 0, generate_files: 5, generate_trajs: 0}}
  ]
